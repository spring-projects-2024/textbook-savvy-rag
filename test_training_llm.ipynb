{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:41.258444Z",
     "start_time": "2024-05-21T21:31:39.141638Z"
    }
   },
   "source": [
    "from backend.model.rag_handler import RagHandler\n",
    "import yaml"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:31:44.062058Z",
     "start_time": "2024-05-21T21:31:41.259456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "with open(\"configs/training/prova.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "device = \"cpu\"\n",
    "model_name = config[\"model_name\"]\n",
    "use_qlora = config[\"use_qlora\"]\n",
    "optimizer_params = config[\"optimizer_params\"]\n",
    "max_epochs = config[\"max_epochs\"]\n",
    "batch_size = config[\"batch_size\"]\n",
    "log_to_wandb = config[\"log_to_wandb\"]\n",
    "log_interval = config[\"log_interval\"]\n",
    "checkpoint_interval = config[\"checkpoint_interval\"]\n",
    "seed = config[\"seed\"]\n",
    "wandb_project = config[\"wandb_project\"]\n",
    "\n",
    "llm_generation_config = config.get(\"llm_generation_config\", {})\n",
    "llm_kwargs = config.get(\"llm_kwargs\", None)\n",
    "tokenizer_kwargs = config.get(\"tokenizer_kwargs\", None)\n",
    "\n",
    "from backend.vector_database.dataset import MockDataset\n",
    "\n",
    "md = MockDataset([\n",
    "    \"ciao\"\n",
    "])\n",
    "faiss_kwargs = {\n",
    "    \"embedder\": None,\n",
    "    \"dataset\": md,\n",
    "    \"index_str\": \"Flat\"\n",
    "\n",
    "}\n",
    "\n",
    "rag_handler = RagHandler(\n",
    "    model_name=model_name,\n",
    "    device=device,\n",
    "    use_qlora=False,\n",
    "    llm_generation_config=llm_generation_config,\n",
    "    llm_kwargs=llm_kwargs,\n",
    "    tokenizer_kwargs=tokenizer_kwargs,\n",
    "    faiss_kwargs=faiss_kwargs,\n",
    ")\n",
    "\n",
    "rag_handler.faiss.train_from_text([\"ciao\"])\n",
    "rag_handler.faiss.add_text([\"ciao\"])\n",
    "# rag_handler.llm.model = prepare_for_qlora(rag_handler.llm.model)\n"
   ],
   "id": "e52770777d07041c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:36:31.337292Z",
     "start_time": "2024-05-21T21:36:30.942734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = \"When did Napoleon die?\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "text = rag_handler.llm.tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# print(text)\n",
    "\n",
    "answer = \"He died in 1821, after long years of exile on the island of Saint Helena.\"\n",
    "\n",
    "batch = {\n",
    "    \"query\": [prompt],\n",
    "\n",
    "    \"answer\": [answer],\n",
    "}\n",
    "\n",
    "res = rag_handler.forward_batch_query_single_doc(batch)"
   ],
   "id": "78e3ae75fe9f4398",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:36:33.100624Z",
     "start_time": "2024-05-21T21:36:33.093947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "token_q = rag_handler.llm.tokenizer(batch[\"query\"], return_tensors=\"pt\")\n",
    "token_a = rag_handler.llm.tokenizer(batch[\"answer\"], return_tensors=\"pt\")\n",
    "\n",
    "token_q, token_a"
   ],
   "id": "b6d78ad093cdf3b5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': tensor([[ 4498,  1521, 69427,  2746,    30]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])},\n",
       " {'input_ids': tensor([[ 1519,  8469,   304,   220,    16,    23,    17,    16,    11,  1283,\n",
       "           1293,  1635,   315, 59987,   389,   279, 12922,   315, 14205, 71946,\n",
       "             13]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:36:33.931359Z",
     "start_time": "2024-05-21T21:36:33.912472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(res[\"logits\"].shape, res[\"answer_lengths\"])\n",
    "\n",
    "answ_len = res[\"answer_lengths\"][0]\n",
    "import torch\n",
    "\n",
    "probs = torch.functional.F.softmax(res[\"logits\"], dim=-1)"
   ],
   "id": "3efb8bd681e1a9e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 78, 151936]) [22]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:36:34.625527Z",
     "start_time": "2024-05-21T21:36:34.618214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# probs[:, -answ_len:, token_a[\"input_ids\"]]\n",
    "rag_handler.llm.tokenizer.eos_token"
   ],
   "id": "bfc245acd0d5ff93",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_end|>'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:36:35.195369Z",
     "start_time": "2024-05-21T21:36:35.168219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# argmax\n",
    "agm = probs.argmax(dim=-1)[:, -answ_len-1:-1]\n"
   ],
   "id": "8a3d42be5c816337",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:36:35.728830Z",
     "start_time": "2024-05-21T21:36:35.719344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# de tokenize\n",
    "true_answ = [rag_handler.llm.tokenizer.decode(x) for x in\n",
    "             rag_handler.llm.tokenizer.encode(answer + rag_handler.llm.tokenizer.eos_token)]\n",
    "pred_answ = [rag_handler.llm.tokenizer.decode(x) for x in agm[0].tolist()]\n",
    "print(true_answ)\n",
    "print(pred_answ)\n",
    "print(len(true_answ), len(pred_answ))"
   ],
   "id": "69c351af17c4135a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He', ' died', ' in', ' ', '1', '8', '2', '1', ',', ' after', ' long', ' years', ' of', ' exile', ' on', ' the', ' island', ' of', ' Saint', ' Helena', '.', '<|im_end|>']\n",
      "['N', ' died', ' on', ' ', '1', '8', '1', '1', '.', ' while', ' a', ' and', ' of', ' military', ' and', ' the', ' island', ' of', ' Saint', '-D', '.', '<|im_end|>']\n",
      "22 22\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:25:23.005787Z",
     "start_time": "2024-05-21T21:25:21.406532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "device = \"cpu\"  # the device to load the model onto\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen1.5-0.5B-Chat\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen1.5-0.5B-Chat\")"
   ],
   "id": "8731257dc72fe80b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:21:12.901679Z",
     "start_time": "2024-05-21T21:21:09.686369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "prompt = \"When did Napoleon die?\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    model_inputs.input_ids,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ],
   "id": "9bfc5e4f78ee0cb",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:21:12.905190Z",
     "start_time": "2024-05-21T21:21:12.902504Z"
    }
   },
   "cell_type": "code",
   "source": "response",
   "id": "7c96c39e95c07e59",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Napoleon was born on April 15, 1804, in Amiens, France. He died on November 13, 1812, while still in power.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8437492c64e722ab"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
